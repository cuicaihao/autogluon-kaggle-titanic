{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd058217fe61dee900240bd4dd377e902ebdf1d2fda5a50143d5c5e32a5cbd9983d",
   "display_name": "Python 3.8.10 64-bit ('AutoGluon': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "58217fe61dee900240bd4dd377e902ebdf1d2fda5a50143d5c5e32a5cbd9983d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Predicting Columns in a Table - Quick Start\n",
    "\n",
    "\n",
    "Source: https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-quickstart.html \n",
    "\n",
    "Via a simple fit() call, AutoGluon can produce highly-accurate models to predict the values in one column of a data table based on the rest of the columns’ values. Use AutoGluon with tabular data for both classification and regression problems. This tutorial demonstrates how to use AutoGluon to produce a classification model that predicts whether or not a person’s income exceeds $50,000.\n",
    "\n",
    "To start, import AutoGluon’s TabularPredictor and TabularDataset classes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "source": [
    "Load training data from a CSV file into an AutoGluon Dataset object. This object is essentially equivalent to a Pandas DataFrame and the same methods can be applied to both."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6118</th>\n      <td>51</td>\n      <td>Private</td>\n      <td>39264</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n    <tr>\n      <th>23204</th>\n      <td>58</td>\n      <td>Private</td>\n      <td>51662</td>\n      <td>10th</td>\n      <td>6</td>\n      <td>Married-civ-spouse</td>\n      <td>Other-service</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>29590</th>\n      <td>40</td>\n      <td>Private</td>\n      <td>326310</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Craft-repair</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>44</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>18116</th>\n      <td>37</td>\n      <td>Private</td>\n      <td>222450</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>2339</td>\n      <td>40</td>\n      <td>El-Salvador</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>33964</th>\n      <td>62</td>\n      <td>Private</td>\n      <td>109190</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>15024</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&gt;50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "source": [
    "Note that we loaded data from a CSV file stored in the cloud (AWS s3 bucket), but you can you specify a local file-path instead if you have already downloaded the CSV file to your own machine (e.g., using wget). Each row in the table train_data corresponds to a single training example. In this particular dataset, each row corresponds to an individual person, and the columns contain various characteristics reported during a census.\n",
    "\n",
    "Let’s first use these features to predict whether the person’s income exceeds $50,000 or not, which is recorded in the class column of this table."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n",
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "source": [
    "Now use AutoGluon to train multiple models:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictClass/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    42574.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.73\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.65\t = Validation accuracy score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t0.99s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.85\t = Validation accuracy score\n",
      "\t0.84s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation accuracy score\n",
      "\t0.47s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.84\t = Validation accuracy score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.82\t = Validation accuracy score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t1.47s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.85\t = Validation accuracy score\n",
      "\t0.44s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.84\t = Validation accuracy score\n",
      "\t5.23s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.83\t = Validation accuracy score\n",
      "\t1.29s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.85\t = Validation accuracy score\n",
      "\t0.38s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.16s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data)"
   ]
  },
  {
   "source": [
    "Next, load separate test data to demonstrate how to make predictions on new examples at inference time:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age          workclass  fnlwgt      education  education-num  \\\n",
       "0   31            Private  169085           11th              7   \n",
       "1   17   Self-emp-not-inc  226203           12th              8   \n",
       "2   47            Private   54260      Assoc-voc             11   \n",
       "3   21            Private  176262   Some-college             10   \n",
       "4   17            Private  241185           12th              8   \n",
       "\n",
       "        marital-status        occupation relationship    race      sex  \\\n",
       "0   Married-civ-spouse             Sales         Wife   White   Female   \n",
       "1        Never-married             Sales    Own-child   White     Male   \n",
       "2   Married-civ-spouse   Exec-managerial      Husband   White     Male   \n",
       "3        Never-married   Exec-managerial    Own-child   White   Female   \n",
       "4        Never-married    Prof-specialty    Own-child   White     Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0             0             0              20   United-States  \n",
       "1             0             0              45   United-States  \n",
       "2             0          1887              60   United-States  \n",
       "3             0             0              30   United-States  \n",
       "4             0             0              20   United-States  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>Private</td>\n      <td>169085</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Wife</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Self-emp-not-inc</td>\n      <td>226203</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Sales</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>54260</td>\n      <td>Assoc-voc</td>\n      <td>11</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>1887</td>\n      <td>60</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>Private</td>\n      <td>176262</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>Exec-managerial</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Private</td>\n      <td>241185</td>\n      <td>12th</td>\n      <td>8</td>\n      <td>Never-married</td>\n      <td>Prof-specialty</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>United-States</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "source": [
    "We use our trained models to make predictions on the new data and then evaluate performance:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Evaluation: accuracy on test data: 0.8397993653393387\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8397993653393387,\n",
      "    \"balanced_accuracy\": 0.7437076677780596,\n",
      "    \"mcc\": 0.5295565206264157,\n",
      "    \"f1\": 0.6242496998799519,\n",
      "    \"precision\": 0.7038440714672441,\n",
      "    \"recall\": 0.5608283002588438\n",
      "}\n",
      "Predictions:  \n",
      " 0        <=50K\n",
      "1        <=50K\n",
      "2         >50K\n",
      "3        <=50K\n",
      "4        <=50K\n",
      "         ...  \n",
      "9764     <=50K\n",
      "9765     <=50K\n",
      "9766     <=50K\n",
      "9767     <=50K\n",
      "9768     <=50K\n",
      "Name: class, Length: 9769, dtype: object\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "source": [
    "We can also evaluate the performance of each individual trained model on our (labeled) test data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0               XGBoost    0.842666       0.85        0.074881       0.006080   \n",
       "1      RandomForestGini    0.841335       0.84        0.076104       0.048978   \n",
       "2      RandomForestEntr    0.840721       0.83        0.074374       0.041690   \n",
       "3              LightGBM    0.839799       0.85        0.041230       0.012507   \n",
       "4   WeightedEnsemble_L2    0.839799       0.85        0.043618       0.013101   \n",
       "5            LightGBMXT    0.839390       0.83        0.021409       0.011018   \n",
       "6              CatBoost    0.837957       0.84        0.017557       0.009680   \n",
       "7        ExtraTreesEntr    0.834783       0.82        0.080310       0.040474   \n",
       "8        ExtraTreesGini    0.834476       0.82        0.101334       0.051537   \n",
       "9         LightGBMLarge    0.827823       0.83        0.033390       0.010490   \n",
       "10       NeuralNetMXNet    0.824752       0.84        0.888399       0.085662   \n",
       "11      NeuralNetFastAI    0.821067       0.83        0.153767       0.034275   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.019652       0.015446   \n",
       "13       KNeighborsDist    0.695158       0.65        0.017896       0.010520   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.437865                 0.074881                0.006080   \n",
       "1   0.468868                 0.076104                0.048978   \n",
       "2   0.407430                 0.074374                0.041690   \n",
       "3   0.838760                 0.041230                0.012507   \n",
       "4   1.222406                 0.002388                0.000594   \n",
       "5   0.992941                 0.021409                0.011018   \n",
       "6   0.683572                 0.017557                0.009680   \n",
       "7   0.407589                 0.080310                0.040474   \n",
       "8   0.410919                 0.101334                0.051537   \n",
       "9   1.293613                 0.033390                0.010490   \n",
       "10  5.228154                 0.888399                0.085662   \n",
       "11  1.472060                 0.153767                0.034275   \n",
       "12  0.004946                 0.019652                0.015446   \n",
       "13  0.003648                 0.017896                0.010520   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.437865            1       True         11  \n",
       "1            0.468868            1       True          5  \n",
       "2            0.407430            1       True          6  \n",
       "3            0.838760            1       True          4  \n",
       "4            0.383646            2       True         14  \n",
       "5            0.992941            1       True          3  \n",
       "6            0.683572            1       True          7  \n",
       "7            0.407589            1       True          9  \n",
       "8            0.410919            1       True          8  \n",
       "9            1.293613            1       True         13  \n",
       "10           5.228154            1       True         12  \n",
       "11           1.472060            1       True         10  \n",
       "12           0.004946            1       True          1  \n",
       "13           0.003648            1       True          2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost</td>\n      <td>0.842666</td>\n      <td>0.85</td>\n      <td>0.074881</td>\n      <td>0.006080</td>\n      <td>0.437865</td>\n      <td>0.074881</td>\n      <td>0.006080</td>\n      <td>0.437865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForestGini</td>\n      <td>0.841335</td>\n      <td>0.84</td>\n      <td>0.076104</td>\n      <td>0.048978</td>\n      <td>0.468868</td>\n      <td>0.076104</td>\n      <td>0.048978</td>\n      <td>0.468868</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.840721</td>\n      <td>0.83</td>\n      <td>0.074374</td>\n      <td>0.041690</td>\n      <td>0.407430</td>\n      <td>0.074374</td>\n      <td>0.041690</td>\n      <td>0.407430</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>0.041230</td>\n      <td>0.012507</td>\n      <td>0.838760</td>\n      <td>0.041230</td>\n      <td>0.012507</td>\n      <td>0.838760</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>0.043618</td>\n      <td>0.013101</td>\n      <td>1.222406</td>\n      <td>0.002388</td>\n      <td>0.000594</td>\n      <td>0.383646</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBMXT</td>\n      <td>0.839390</td>\n      <td>0.83</td>\n      <td>0.021409</td>\n      <td>0.011018</td>\n      <td>0.992941</td>\n      <td>0.021409</td>\n      <td>0.011018</td>\n      <td>0.992941</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CatBoost</td>\n      <td>0.837957</td>\n      <td>0.84</td>\n      <td>0.017557</td>\n      <td>0.009680</td>\n      <td>0.683572</td>\n      <td>0.017557</td>\n      <td>0.009680</td>\n      <td>0.683572</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.834783</td>\n      <td>0.82</td>\n      <td>0.080310</td>\n      <td>0.040474</td>\n      <td>0.407589</td>\n      <td>0.080310</td>\n      <td>0.040474</td>\n      <td>0.407589</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesGini</td>\n      <td>0.834476</td>\n      <td>0.82</td>\n      <td>0.101334</td>\n      <td>0.051537</td>\n      <td>0.410919</td>\n      <td>0.101334</td>\n      <td>0.051537</td>\n      <td>0.410919</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBMLarge</td>\n      <td>0.827823</td>\n      <td>0.83</td>\n      <td>0.033390</td>\n      <td>0.010490</td>\n      <td>1.293613</td>\n      <td>0.033390</td>\n      <td>0.010490</td>\n      <td>1.293613</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NeuralNetMXNet</td>\n      <td>0.824752</td>\n      <td>0.84</td>\n      <td>0.888399</td>\n      <td>0.085662</td>\n      <td>5.228154</td>\n      <td>0.888399</td>\n      <td>0.085662</td>\n      <td>5.228154</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.821067</td>\n      <td>0.83</td>\n      <td>0.153767</td>\n      <td>0.034275</td>\n      <td>1.472060</td>\n      <td>0.153767</td>\n      <td>0.034275</td>\n      <td>1.472060</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>0.019652</td>\n      <td>0.015446</td>\n      <td>0.004946</td>\n      <td>0.019652</td>\n      <td>0.015446</td>\n      <td>0.004946</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>0.017896</td>\n      <td>0.010520</td>\n      <td>0.003648</td>\n      <td>0.017896</td>\n      <td>0.010520</td>\n      <td>0.003648</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)\n"
   ]
  },
  {
   "source": [
    "Now you’re ready to try AutoGluon on your own tabular datasets! As long as they’re stored in a popular format like CSV, you should be able to achieve strong predictive performance with just 2 lines of code:\n",
    "\n",
    "```python\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=<variable-name>).fit(train_data=<file-name>)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Description of fit():\n",
    "\n",
    "Here we discuss what happened during fit().\n",
    "\n",
    "Since there are only two possible values of the class variable, this was a binary classification problem, for which an appropriate performance metric is accuracy. AutoGluon automatically infers this as well as the type of each feature (i.e., which columns contain continuous numbers vs. discrete categories). AutogGluon can also automatically handle common issues like missing data and rescaling feature values.\n",
    "\n",
    "We did not specify separate validation data and so AutoGluon automatically choses a random training/validation split of the data. The data used for validation is seperated from the training data and is used to determine the models and hyperparameter-values that produce the best results. Rather than just a single model, AutoGluon trains multiple models and ensembles them together to ensure superior predictive performance.\n",
    "\n",
    "By default, AutoGluon tries to fit various types of models including neural networks and tree ensembles. Each type of model has various hyperparameters, which traditionally, the user would have to specify. AutoGluon automates this process.\n",
    "\n",
    "AutoGluon automatically and iteratively tests values for hyperparameters to produce the best performance on the validation data. This involves repeatedly training models under different hyperparameter settings and evaluating their performance. This process can be computationally-intensive, so fit() can parallelize this process across multiple threads (and machines if distributed resources are available). To control runtimes, you can specify various arguments in fit() as demonstrated in the subsequent In-Depth tutorial.\n",
    "\n",
    "For tabular problems, fit() returns a Predictor object. For classification, you can easily output predicted class probabilities instead of predicted classes:\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      <=50K      >50K\n",
       "0  0.949797  0.050203\n",
       "1  0.945973  0.054027\n",
       "2  0.433299  0.566701\n",
       "3  0.991393  0.008607\n",
       "4  0.949908  0.050092"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>&lt;=50K</th>\n      <th>&gt;50K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.949797</td>\n      <td>0.050203</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.945973</td>\n      <td>0.054027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.433299</td>\n      <td>0.566701</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.991393</td>\n      <td>0.008607</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.949908</td>\n      <td>0.050092</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pred_probs = predictor.predict_proba(test_data_nolab)\n",
    "pred_probs.head(5)"
   ]
  },
  {
   "source": [
    "Besides inference, this object can also summarize what happened during fit.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2   0.900294       0.352193  10.805357                0.001113           1.266509            2       True         14\n",
      "1     ExtraTreesEntr_BAG_L1   0.893912       0.092358   0.394143                0.092358           0.394143            1       True          9\n",
      "2     ExtraTreesGini_BAG_L1   0.892927       0.092565   0.392809                0.092565           0.392809            1       True          8\n",
      "3           CatBoost_BAG_L1   0.887489       0.043027   5.326382                0.043027           5.326382            1       True          7\n",
      "4   RandomForestEntr_BAG_L1   0.886301       0.091141   0.389914                0.091141           0.389914            1       True          6\n",
      "5   RandomForestGini_BAG_L1   0.884698       0.091445   0.402679                0.091445           0.402679            1       True          5\n",
      "6         LightGBMXT_BAG_L1   0.881380       0.054929   3.156310                0.054929           3.156310            1       True          3\n",
      "7           LightGBM_BAG_L1   0.866991       0.051534   3.252953                0.051534           3.252953            1       True          4\n",
      "8            XGBoost_BAG_L1   0.866575       0.030624   1.932197                0.030624           1.932197            1       True         11\n",
      "9    NeuralNetFastAI_BAG_L1   0.866565       0.123130   3.425514                0.123130           3.425514            1       True         10\n",
      "10    NeuralNetMXNet_BAG_L1   0.858874       0.576055  25.368728                0.576055          25.368728            1       True         12\n",
      "11     LightGBMLarge_BAG_L1   0.841684       0.051192   8.963324                0.051192           8.963324            1       True         13\n",
      "12    KNeighborsDist_BAG_L1   0.536956       0.009384   0.002922                0.009384           0.002922            1       True          2\n",
      "13    KNeighborsUnif_BAG_L1   0.519604       0.009541   0.004635                0.009541           0.004635            1       True          1\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_TabularNeuralNet', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20210515_021854/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()\n"
   ]
  },
  {
   "source": [
    "From this summary, we can see that AutoGluon trained many different types of models as well as an ensemble of the best-performing models. The summary also describes the actual models that were trained during fit and how well each model performed on the held-out validation data. We can view what properties AutoGluon automatically inferred about our prediction task:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "source": [
    "AutoGluon correctly recognized our prediction problem to be a binary classification task and decided that variables such as age should be represented as integers, whereas variables such as workclass should be represented as categorical objects. The feature_metadata attribute allows you to see the inferred data type of each predictive variable after preprocessing (this is it’s raw dtype; some features may also be associated with additional special dtypes if produced via feature-engineering, e.g. numerical representations of a datetime/text column).\n",
    "\n",
    "We can evaluate the performance of each individual trained model on our (labeled) test data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0               XGBoost    0.842666       0.85        0.077081       0.006080   \n",
       "1      RandomForestGini    0.841335       0.84        0.076173       0.048978   \n",
       "2      RandomForestEntr    0.840721       0.83        0.075019       0.041690   \n",
       "3              LightGBM    0.839799       0.85        0.027496       0.012507   \n",
       "4   WeightedEnsemble_L2    0.839799       0.85        0.029425       0.013101   \n",
       "5            LightGBMXT    0.839390       0.83        0.022646       0.011018   \n",
       "6              CatBoost    0.837957       0.84        0.017645       0.009680   \n",
       "7        ExtraTreesEntr    0.834783       0.82        0.079481       0.040474   \n",
       "8        ExtraTreesGini    0.834476       0.82        0.083868       0.051537   \n",
       "9         LightGBMLarge    0.827823       0.83        0.028883       0.010490   \n",
       "10       NeuralNetMXNet    0.824752       0.84        0.868563       0.085662   \n",
       "11      NeuralNetFastAI    0.821067       0.83        0.156452       0.034275   \n",
       "12       KNeighborsUnif    0.725970       0.73        0.016587       0.015446   \n",
       "13       KNeighborsDist    0.695158       0.65        0.016510       0.010520   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.437865                 0.077081                0.006080   \n",
       "1   0.468868                 0.076173                0.048978   \n",
       "2   0.407430                 0.075019                0.041690   \n",
       "3   0.838760                 0.027496                0.012507   \n",
       "4   1.222406                 0.001929                0.000594   \n",
       "5   0.992941                 0.022646                0.011018   \n",
       "6   0.683572                 0.017645                0.009680   \n",
       "7   0.407589                 0.079481                0.040474   \n",
       "8   0.410919                 0.083868                0.051537   \n",
       "9   1.293613                 0.028883                0.010490   \n",
       "10  5.228154                 0.868563                0.085662   \n",
       "11  1.472060                 0.156452                0.034275   \n",
       "12  0.004946                 0.016587                0.015446   \n",
       "13  0.003648                 0.016510                0.010520   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.437865            1       True         11  \n",
       "1            0.468868            1       True          5  \n",
       "2            0.407430            1       True          6  \n",
       "3            0.838760            1       True          4  \n",
       "4            0.383646            2       True         14  \n",
       "5            0.992941            1       True          3  \n",
       "6            0.683572            1       True          7  \n",
       "7            0.407589            1       True          9  \n",
       "8            0.410919            1       True          8  \n",
       "9            1.293613            1       True         13  \n",
       "10           5.228154            1       True         12  \n",
       "11           1.472060            1       True         10  \n",
       "12           0.004946            1       True          1  \n",
       "13           0.003648            1       True          2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost</td>\n      <td>0.842666</td>\n      <td>0.85</td>\n      <td>0.077081</td>\n      <td>0.006080</td>\n      <td>0.437865</td>\n      <td>0.077081</td>\n      <td>0.006080</td>\n      <td>0.437865</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RandomForestGini</td>\n      <td>0.841335</td>\n      <td>0.84</td>\n      <td>0.076173</td>\n      <td>0.048978</td>\n      <td>0.468868</td>\n      <td>0.076173</td>\n      <td>0.048978</td>\n      <td>0.468868</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestEntr</td>\n      <td>0.840721</td>\n      <td>0.83</td>\n      <td>0.075019</td>\n      <td>0.041690</td>\n      <td>0.407430</td>\n      <td>0.075019</td>\n      <td>0.041690</td>\n      <td>0.407430</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>0.027496</td>\n      <td>0.012507</td>\n      <td>0.838760</td>\n      <td>0.027496</td>\n      <td>0.012507</td>\n      <td>0.838760</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.839799</td>\n      <td>0.85</td>\n      <td>0.029425</td>\n      <td>0.013101</td>\n      <td>1.222406</td>\n      <td>0.001929</td>\n      <td>0.000594</td>\n      <td>0.383646</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBMXT</td>\n      <td>0.839390</td>\n      <td>0.83</td>\n      <td>0.022646</td>\n      <td>0.011018</td>\n      <td>0.992941</td>\n      <td>0.022646</td>\n      <td>0.011018</td>\n      <td>0.992941</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CatBoost</td>\n      <td>0.837957</td>\n      <td>0.84</td>\n      <td>0.017645</td>\n      <td>0.009680</td>\n      <td>0.683572</td>\n      <td>0.017645</td>\n      <td>0.009680</td>\n      <td>0.683572</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesEntr</td>\n      <td>0.834783</td>\n      <td>0.82</td>\n      <td>0.079481</td>\n      <td>0.040474</td>\n      <td>0.407589</td>\n      <td>0.079481</td>\n      <td>0.040474</td>\n      <td>0.407589</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesGini</td>\n      <td>0.834476</td>\n      <td>0.82</td>\n      <td>0.083868</td>\n      <td>0.051537</td>\n      <td>0.410919</td>\n      <td>0.083868</td>\n      <td>0.051537</td>\n      <td>0.410919</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBMLarge</td>\n      <td>0.827823</td>\n      <td>0.83</td>\n      <td>0.028883</td>\n      <td>0.010490</td>\n      <td>1.293613</td>\n      <td>0.028883</td>\n      <td>0.010490</td>\n      <td>1.293613</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NeuralNetMXNet</td>\n      <td>0.824752</td>\n      <td>0.84</td>\n      <td>0.868563</td>\n      <td>0.085662</td>\n      <td>5.228154</td>\n      <td>0.868563</td>\n      <td>0.085662</td>\n      <td>5.228154</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>0.821067</td>\n      <td>0.83</td>\n      <td>0.156452</td>\n      <td>0.034275</td>\n      <td>1.472060</td>\n      <td>0.156452</td>\n      <td>0.034275</td>\n      <td>1.472060</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsUnif</td>\n      <td>0.725970</td>\n      <td>0.73</td>\n      <td>0.016587</td>\n      <td>0.015446</td>\n      <td>0.004946</td>\n      <td>0.016587</td>\n      <td>0.015446</td>\n      <td>0.004946</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsDist</td>\n      <td>0.695158</td>\n      <td>0.65</td>\n      <td>0.016510</td>\n      <td>0.010520</td>\n      <td>0.003648</td>\n      <td>0.016510</td>\n      <td>0.010520</td>\n      <td>0.003648</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)\n"
   ]
  },
  {
   "source": [
    "When we call predict(), AutoGluon automatically predicts with the model that displayed the best performance on validation data (i.e. the weighted-ensemble). We can instead specify which model to use for predictions like this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2         >50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "predictor.predict(test_data, model='LightGBM')\n"
   ]
  },
  {
   "source": [
    "Above the scores of predictive performance were based on a default evaluation metric (accuracy for binary classification). Performance in certain applications may be measured by different metrics than the ones AutoGluon optimizes for by default. If you know the metric that counts in your application, you should specify it as demonstrated in the next section."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Maximizing predictive performance\n",
    "Note: You should not call fit() with entirely default arguments if you are benchmarking AutoGluon-Tabular or hoping to maximize its accuracy! To get the best predictive accuracy with AutoGluon, you should generally use it like this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210515_021854/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210515_021854/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    42510.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])      : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.91s of the 59.91s of remaining time.\n",
      "\t0.5196\t = Validation roc_auc score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.89s of the 59.88s of remaining time.\n",
      "\t0.537\t = Validation roc_auc score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 59.86s of the 59.86s of remaining time.\n",
      "\t0.8814\t = Validation roc_auc score\n",
      "\t3.16s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 56.62s of the 56.62s of remaining time.\n",
      "\t0.867\t = Validation roc_auc score\n",
      "\t3.25s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 53.3s of the 53.3s of remaining time.\n",
      "\t0.8847\t = Validation roc_auc score\n",
      "\t0.4s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 52.79s of the 52.78s of remaining time.\n",
      "\t0.8863\t = Validation roc_auc score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 52.29s of the 52.28s of remaining time.\n",
      "\t0.8875\t = Validation roc_auc score\n",
      "\t5.33s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 46.9s of the 46.9s of remaining time.\n",
      "\t0.8929\t = Validation roc_auc score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 46.39s of the 46.39s of remaining time.\n",
      "\t0.8939\t = Validation roc_auc score\n",
      "\t0.39s\t = Training runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 45.89s of the 45.88s of remaining time.\n",
      "\t0.8666\t = Validation roc_auc score\n",
      "\t3.43s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 42.28s of the 42.28s of remaining time.\n",
      "\t0.8666\t = Validation roc_auc score\n",
      "\t1.93s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 40.2s of the 40.19s of remaining time.\n",
      "\t0.8589\t = Validation roc_auc score\n",
      "\t25.37s\t = Training runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 14.22s of the 14.21s of remaining time.\n",
      "\t0.8417\t = Validation roc_auc score\n",
      "\t8.96s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.91s of the 5.16s of remaining time.\n",
      "\t0.9003\t = Validation roc_auc score\n",
      "\t1.27s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 56.13s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210515_021854/\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0           CatBoost_BAG_L1    0.902783   0.887489        0.070385   \n",
       "1         LightGBMXT_BAG_L1    0.900161   0.881380        0.208763   \n",
       "2       WeightedEnsemble_L2    0.894506   0.900294        0.991615   \n",
       "3           LightGBM_BAG_L1    0.892347   0.866991        0.117996   \n",
       "4            XGBoost_BAG_L1    0.891681   0.866575        0.363181   \n",
       "5   RandomForestEntr_BAG_L1    0.888119   0.886301        0.088699   \n",
       "6   RandomForestGini_BAG_L1    0.886598   0.884698        0.078156   \n",
       "7    NeuralNetFastAI_BAG_L1    0.882037   0.866565        0.731166   \n",
       "8     ExtraTreesGini_BAG_L1    0.881065   0.892927        0.094910   \n",
       "9     ExtraTreesEntr_BAG_L1    0.880851   0.893912        0.092406   \n",
       "10     LightGBMLarge_BAG_L1    0.873756   0.841684        0.138365   \n",
       "11    NeuralNetMXNet_BAG_L1    0.865415   0.858874        4.474139   \n",
       "12    KNeighborsDist_BAG_L1    0.525998   0.536956        0.014692   \n",
       "13    KNeighborsUnif_BAG_L1    0.514970   0.519604        0.014053   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.043027   5.326382                 0.070385                0.043027   \n",
       "1        0.054929   3.156310                 0.208763                0.054929   \n",
       "2        0.352193  10.805357                 0.002748                0.001113   \n",
       "3        0.051534   3.252953                 0.117996                0.051534   \n",
       "4        0.030624   1.932197                 0.363181                0.030624   \n",
       "5        0.091141   0.389914                 0.088699                0.091141   \n",
       "6        0.091445   0.402679                 0.078156                0.091445   \n",
       "7        0.123130   3.425514                 0.731166                0.123130   \n",
       "8        0.092565   0.392809                 0.094910                0.092565   \n",
       "9        0.092358   0.394143                 0.092406                0.092358   \n",
       "10       0.051192   8.963324                 0.138365                0.051192   \n",
       "11       0.576055  25.368728                 4.474139                0.576055   \n",
       "12       0.009384   0.002922                 0.014692                0.009384   \n",
       "13       0.009541   0.004635                 0.014053                0.009541   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            5.326382            1       True          7  \n",
       "1            3.156310            1       True          3  \n",
       "2            1.266509            2       True         14  \n",
       "3            3.252953            1       True          4  \n",
       "4            1.932197            1       True         11  \n",
       "5            0.389914            1       True          6  \n",
       "6            0.402679            1       True          5  \n",
       "7            3.425514            1       True         10  \n",
       "8            0.392809            1       True          8  \n",
       "9            0.394143            1       True          9  \n",
       "10           8.963324            1       True         13  \n",
       "11          25.368728            1       True         12  \n",
       "12           0.002922            1       True          2  \n",
       "13           0.004635            1       True          1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CatBoost_BAG_L1</td>\n      <td>0.902783</td>\n      <td>0.887489</td>\n      <td>0.070385</td>\n      <td>0.043027</td>\n      <td>5.326382</td>\n      <td>0.070385</td>\n      <td>0.043027</td>\n      <td>5.326382</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>0.900161</td>\n      <td>0.881380</td>\n      <td>0.208763</td>\n      <td>0.054929</td>\n      <td>3.156310</td>\n      <td>0.208763</td>\n      <td>0.054929</td>\n      <td>3.156310</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.894506</td>\n      <td>0.900294</td>\n      <td>0.991615</td>\n      <td>0.352193</td>\n      <td>10.805357</td>\n      <td>0.002748</td>\n      <td>0.001113</td>\n      <td>1.266509</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.892347</td>\n      <td>0.866991</td>\n      <td>0.117996</td>\n      <td>0.051534</td>\n      <td>3.252953</td>\n      <td>0.117996</td>\n      <td>0.051534</td>\n      <td>3.252953</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XGBoost_BAG_L1</td>\n      <td>0.891681</td>\n      <td>0.866575</td>\n      <td>0.363181</td>\n      <td>0.030624</td>\n      <td>1.932197</td>\n      <td>0.363181</td>\n      <td>0.030624</td>\n      <td>1.932197</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForestEntr_BAG_L1</td>\n      <td>0.888119</td>\n      <td>0.886301</td>\n      <td>0.088699</td>\n      <td>0.091141</td>\n      <td>0.389914</td>\n      <td>0.088699</td>\n      <td>0.091141</td>\n      <td>0.389914</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RandomForestGini_BAG_L1</td>\n      <td>0.886598</td>\n      <td>0.884698</td>\n      <td>0.078156</td>\n      <td>0.091445</td>\n      <td>0.402679</td>\n      <td>0.078156</td>\n      <td>0.091445</td>\n      <td>0.402679</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.882037</td>\n      <td>0.866565</td>\n      <td>0.731166</td>\n      <td>0.123130</td>\n      <td>3.425514</td>\n      <td>0.731166</td>\n      <td>0.123130</td>\n      <td>3.425514</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesGini_BAG_L1</td>\n      <td>0.881065</td>\n      <td>0.892927</td>\n      <td>0.094910</td>\n      <td>0.092565</td>\n      <td>0.392809</td>\n      <td>0.094910</td>\n      <td>0.092565</td>\n      <td>0.392809</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ExtraTreesEntr_BAG_L1</td>\n      <td>0.880851</td>\n      <td>0.893912</td>\n      <td>0.092406</td>\n      <td>0.092358</td>\n      <td>0.394143</td>\n      <td>0.092406</td>\n      <td>0.092358</td>\n      <td>0.394143</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBMLarge_BAG_L1</td>\n      <td>0.873756</td>\n      <td>0.841684</td>\n      <td>0.138365</td>\n      <td>0.051192</td>\n      <td>8.963324</td>\n      <td>0.138365</td>\n      <td>0.051192</td>\n      <td>8.963324</td>\n      <td>1</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetMXNet_BAG_L1</td>\n      <td>0.865415</td>\n      <td>0.858874</td>\n      <td>4.474139</td>\n      <td>0.576055</td>\n      <td>25.368728</td>\n      <td>4.474139</td>\n      <td>0.576055</td>\n      <td>25.368728</td>\n      <td>1</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.525998</td>\n      <td>0.536956</td>\n      <td>0.014692</td>\n      <td>0.009384</td>\n      <td>0.002922</td>\n      <td>0.014692</td>\n      <td>0.009384</td>\n      <td>0.002922</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.514970</td>\n      <td>0.519604</td>\n      <td>0.014053</td>\n      <td>0.009541</td>\n      <td>0.004635</td>\n      <td>0.014053</td>\n      <td>0.009541</td>\n      <td>0.004635</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "source": [
    "This command implements the following strategy to maximize accuracy:\n",
    "\n",
    "Specify the argument presets='best_quality', which allows AutoGluon to automatically construct powerful model ensembles based on stacking/bagging, and will greatly improve the resulting predictions if granted sufficient training time. The default value of presets is 'medium_quality_faster_train', which produces less accurate models but facilitates faster prototyping. With presets, you can flexibly prioritize predictive accuracy vs. training/inference speed. For example, if you care less about predictive performance and want to quickly deploy a basic model, consider using: presets=['good_quality_faster_inference_only_refit', 'optimize_for_deployment'].\n",
    "\n",
    "- Provide the eval_metric if you know what metric will be used to evaluate predictions in your application. Some other non-default metrics you might use include things like: 'f1' (for binary classification), 'roc_auc' (for binary classification), 'log_loss' (for classification), 'mean_absolute_error' (for regression), 'median_absolute_error' (for regression). You can also define your own custom metric function, see examples in the folder: autogluon/core/metrics/\n",
    "\n",
    "- Include all your data in train_data and do not provide tuning_data (AutoGluon will split the data more intelligently to fit its needs).\n",
    "\n",
    "- Do not specify the hyperparameter_tune_kwargs argument (counterintuitively, hyperparameter tuning is not the best way to spend a limited training time budgets, as model ensembling is often superior). We recommend you only use hyperparameter_tune_kwargs if your goal is to deploy a single model rather than an ensemble.\n",
    "\n",
    "- Do not specify hyperparameters argument (allow AutoGluon to adaptively select which models/hyperparameters to use).\n",
    "\n",
    "- Set time_limit to the longest amount of time (in seconds) that you are willing to wait. AutoGluon’s predictive performance improves the longer fit() is allowed to run."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Regression (predicting numeric table columns):\n",
    "To demonstrate that fit() can also automatically handle regression tasks, we now try to predict the numeric age variable in the same table based on the other features:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of age variable: \n",
      " count    500.00000\n",
      "mean      39.65200\n",
      "std       13.52393\n",
      "min       17.00000\n",
      "25%       29.00000\n",
      "50%       38.00000\n",
      "75%       49.00000\n",
      "max       85.00000\n",
      "Name: age, dtype: float64\n",
      "/Users/caihaocui/opt/miniconda3/envs/AutoGluon/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "age_column = 'age'\n",
    "print(\"Summary of age variable: \\n\", train_data[age_column].describe())"
   ]
  },
  {
   "source": [
    "We again call fit(), imposing a time-limit this time (in seconds), and also demonstrate a shorthand method to evaluate the resulting model on the test data (which contain labels):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"agModels-predictAge/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (85, 17, 39.652, 13.52393)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    42354.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 9 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 9 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])      : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 59.9s of the 59.9s of remaining time.\n",
      "\t-15.6869\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 59.89s of the 59.89s of remaining time.\n",
      "\t-15.1801\t = Validation root_mean_squared_error score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.87s of the 59.87s of remaining time.\n",
      "\t-11.8147\t = Validation root_mean_squared_error score\n",
      "\t1.17s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 58.68s of the 58.68s of remaining time.\n",
      "\t-11.9295\t = Validation root_mean_squared_error score\n",
      "\t0.84s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 57.82s of the 57.82s of remaining time.\n",
      "\t-11.6028\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 57.39s of the 57.39s of remaining time.\n",
      "\t-11.7448\t = Validation root_mean_squared_error score\n",
      "\t0.68s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 56.7s of the 56.7s of remaining time.\n",
      "\t-11.4808\t = Validation root_mean_squared_error score\n",
      "\t0.37s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 56.29s of the 56.28s of remaining time.\n",
      "\t-40.4584\t = Validation root_mean_squared_error score\n",
      "\t0.72s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 55.53s of the 55.53s of remaining time.\n",
      "\t-12.1743\t = Validation root_mean_squared_error score\n",
      "\t0.58s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ... Training model for up to 54.9s of the 54.9s of remaining time.\n",
      "\t-13.1693\t = Validation root_mean_squared_error score\n",
      "\t3.28s\t = Training runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 51.49s of the 51.49s of remaining time.\n",
      "\t-12.1676\t = Validation root_mean_squared_error score\n",
      "\t2.86s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.9s of the 48.21s of remaining time.\n",
      "\t-11.3138\t = Validation root_mean_squared_error score\n",
      "\t0.41s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.22s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictAge/\")\n",
      "Evaluation: root_mean_squared_error on test data: -10.534319496521219\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -10.534319496521219,\n",
      "    \"mean_squared_error\": -110.97188725478705,\n",
      "    \"mean_absolute_error\": -8.329341894285085,\n",
      "    \"r2\": 0.40683372078682956,\n",
      "    \"pearsonr\": 0.6413939917186744,\n",
      "    \"median_absolute_error\": -7.011096954345703\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "predictor_age = TabularPredictor(label=age_column, path=\"agModels-predictAge\").fit(train_data, time_limit=60)\n",
    "performance = predictor_age.evaluate(test_data)"
   ]
  },
  {
   "source": [
    "Note that we didn’t need to tell AutoGluon this is a regression problem, it automatically inferred this from the data and reported the appropriate performance metric (RMSE by default). To specify a particular evaluation metric other than the default, set the eval_metric argument of fit() and AutoGluon will tailor its models to optimize your metric (e.g. eval_metric = 'mean_absolute_error'). For evaluation metrics where higher values are worse (like RMSE), AutoGluon may sometimes flips their sign and print them as negative values during training (as it internally assumes higher values are better).\n",
    "\n",
    "We can call leaderboard to see the per-model performance:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2  -10.534319 -11.313772        1.273746       0.230337   \n",
       "1         ExtraTreesMSE  -10.691115 -11.480752        0.072538       0.035789   \n",
       "2       RandomForestMSE  -10.746518 -11.602848        0.068356       0.034627   \n",
       "3            LightGBMXT  -10.753344 -11.814712        0.045171       0.012330   \n",
       "4              CatBoost  -10.800412 -11.744795        0.019409       0.009434   \n",
       "5              LightGBM  -10.972156 -11.929546        0.023109       0.012057   \n",
       "6               XGBoost  -11.121008 -12.174270        0.091314       0.006893   \n",
       "7         LightGBMLarge  -11.598649 -12.167606        0.050763       0.011821   \n",
       "8        NeuralNetMXNet  -13.003221 -13.169344        0.949260       0.118719   \n",
       "9        KNeighborsUnif  -14.902058 -15.686937        0.014174       0.012266   \n",
       "10       KNeighborsDist  -15.771259 -15.180149        0.016496       0.008575   \n",
       "11      NeuralNetFastAI  -39.159195 -40.458364        0.170738       0.026514   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   7.705367                 0.004589                0.000488   \n",
       "1   0.365046                 0.072538                0.035789   \n",
       "2   0.373121                 0.068356                0.034627   \n",
       "3   1.172688                 0.045171                0.012330   \n",
       "4   0.678361                 0.019409                0.009434   \n",
       "5   0.840785                 0.023109                0.012057   \n",
       "6   0.582656                 0.091314                0.006893   \n",
       "7   2.860899                 0.050763                0.011821   \n",
       "8   3.282897                 0.949260                0.118719   \n",
       "9   0.002818                 0.014174                0.012266   \n",
       "10  0.003048                 0.016496                0.008575   \n",
       "11  0.716945                 0.170738                0.026514   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.409813            2       True         12  \n",
       "1            0.365046            1       True          7  \n",
       "2            0.373121            1       True          5  \n",
       "3            1.172688            1       True          3  \n",
       "4            0.678361            1       True          6  \n",
       "5            0.840785            1       True          4  \n",
       "6            0.582656            1       True          9  \n",
       "7            2.860899            1       True         11  \n",
       "8            3.282897            1       True         10  \n",
       "9            0.002818            1       True          1  \n",
       "10           0.003048            1       True          2  \n",
       "11           0.716945            1       True          8  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-10.534319</td>\n      <td>-11.313772</td>\n      <td>1.273746</td>\n      <td>0.230337</td>\n      <td>7.705367</td>\n      <td>0.004589</td>\n      <td>0.000488</td>\n      <td>0.409813</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ExtraTreesMSE</td>\n      <td>-10.691115</td>\n      <td>-11.480752</td>\n      <td>0.072538</td>\n      <td>0.035789</td>\n      <td>0.365046</td>\n      <td>0.072538</td>\n      <td>0.035789</td>\n      <td>0.365046</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestMSE</td>\n      <td>-10.746518</td>\n      <td>-11.602848</td>\n      <td>0.068356</td>\n      <td>0.034627</td>\n      <td>0.373121</td>\n      <td>0.068356</td>\n      <td>0.034627</td>\n      <td>0.373121</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBMXT</td>\n      <td>-10.753344</td>\n      <td>-11.814712</td>\n      <td>0.045171</td>\n      <td>0.012330</td>\n      <td>1.172688</td>\n      <td>0.045171</td>\n      <td>0.012330</td>\n      <td>1.172688</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CatBoost</td>\n      <td>-10.800412</td>\n      <td>-11.744795</td>\n      <td>0.019409</td>\n      <td>0.009434</td>\n      <td>0.678361</td>\n      <td>0.019409</td>\n      <td>0.009434</td>\n      <td>0.678361</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>-10.972156</td>\n      <td>-11.929546</td>\n      <td>0.023109</td>\n      <td>0.012057</td>\n      <td>0.840785</td>\n      <td>0.023109</td>\n      <td>0.012057</td>\n      <td>0.840785</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>XGBoost</td>\n      <td>-11.121008</td>\n      <td>-12.174270</td>\n      <td>0.091314</td>\n      <td>0.006893</td>\n      <td>0.582656</td>\n      <td>0.091314</td>\n      <td>0.006893</td>\n      <td>0.582656</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LightGBMLarge</td>\n      <td>-11.598649</td>\n      <td>-12.167606</td>\n      <td>0.050763</td>\n      <td>0.011821</td>\n      <td>2.860899</td>\n      <td>0.050763</td>\n      <td>0.011821</td>\n      <td>2.860899</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NeuralNetMXNet</td>\n      <td>-13.003221</td>\n      <td>-13.169344</td>\n      <td>0.949260</td>\n      <td>0.118719</td>\n      <td>3.282897</td>\n      <td>0.949260</td>\n      <td>0.118719</td>\n      <td>3.282897</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>KNeighborsUnif</td>\n      <td>-14.902058</td>\n      <td>-15.686937</td>\n      <td>0.014174</td>\n      <td>0.012266</td>\n      <td>0.002818</td>\n      <td>0.014174</td>\n      <td>0.012266</td>\n      <td>0.002818</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsDist</td>\n      <td>-15.771259</td>\n      <td>-15.180149</td>\n      <td>0.016496</td>\n      <td>0.008575</td>\n      <td>0.003048</td>\n      <td>0.016496</td>\n      <td>0.008575</td>\n      <td>0.003048</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetFastAI</td>\n      <td>-39.159195</td>\n      <td>-40.458364</td>\n      <td>0.170738</td>\n      <td>0.026514</td>\n      <td>0.716945</td>\n      <td>0.170738</td>\n      <td>0.026514</td>\n      <td>0.716945</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "predictor_age.leaderboard(test_data, silent=True)\n"
   ]
  },
  {
   "source": [
    "Data Formats: AutoGluon can currently operate on data tables already loaded into Python as pandas DataFrames, or those stored in files of CSV format or Parquet format. If your data live in multiple tables, you will first need to join them into a single table whose rows correspond to statistically independent observations (datapoints) and columns correspond to different features (aka. variables/covariates).\n",
    "\n",
    "Refer to the TabularPredictor documentation to see all of the available methods/options."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}